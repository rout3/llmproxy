llm_proxy:
  name: LLM proxy API
  version: demo 1.0
  description: An API that act as a proxy to multiple language models

proxy_configuration:
  route_type: cost

optional_configuration:
  timeout: 10 # Timeout for request to models
  force_timeout: true # WARNING: This can cause additonal costs!

provider_settings:
  - provider: OpenAI
    api_key_var: OPENAI_API_KEY # .env name for api key
    max_output_tokens: 10000
    temperature: 1.0
    models:
      - test_model_that_is_not_supported
      - gpt-3.5-turbo-instruct
      - gpt-4-32k

  - provider: Llama2
    class: proxyllm.provider.huggingface.llama2.Llama2
    models:
      - name: Llama-2-7b-chat-hf
        cost_per_hour: 0.06
      - name: Llama-2-13b-chat-hf
        cost_per_hour: 0.06
      - name: Llama-2-70b-chat-hf
        cost_per_hour: 0.06

  - provider: Mistral
    class: proxyllm.provider.mistral.mistral.Mistral
    models:
      - name: Mistral-7B-v0.1
        cost_per_hour: 0.06
      - name: Mistral-7B-Instruct-v0.1
        cost_per_hour: 0.06